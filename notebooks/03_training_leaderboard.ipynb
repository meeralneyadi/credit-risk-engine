{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8360c818",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, HistGradientBoostingClassifier\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, log_loss,\n",
    "    brier_score_loss, confusion_matrix\n",
    ")\n",
    "\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88871f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: (24000, 24) X_val: (6000, 24)\n",
      "y_train: (24000,) y_val: (6000,)\n"
     ]
    }
   ],
   "source": [
    "PROCESSED_PATH = \"../data/processed/\"\n",
    "\n",
    "X_train = pd.read_csv(PROCESSED_PATH + \"X_train.csv\")\n",
    "X_val   = pd.read_csv(PROCESSED_PATH + \"X_val.csv\")\n",
    "y_train = pd.read_csv(PROCESSED_PATH + \"y_train.csv\").squeeze(\"columns\")\n",
    "y_val   = pd.read_csv(PROCESSED_PATH + \"y_val.csv\").squeeze(\"columns\")\n",
    "\n",
    "print(\"X_train:\", X_train.shape, \"X_val:\", X_val.shape)\n",
    "print(\"y_train:\", y_train.shape, \"y_val:\", y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1f1a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ks_statistic(y_true, y_prob):\n",
    "    # KS = max difference between CDFs of positives and negatives\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "    order = np.argsort(y_prob)\n",
    "    y_true_sorted = y_true[order]\n",
    "\n",
    "    pos = (y_true_sorted == 1).astype(int)\n",
    "    neg = (y_true_sorted == 0).astype(int)\n",
    "\n",
    "    cdf_pos = np.cumsum(pos) / max(pos.sum(), 1)\n",
    "    cdf_neg = np.cumsum(neg) / max(neg.sum(), 1)\n",
    "    return float(np.max(np.abs(cdf_pos - cdf_neg)))\n",
    "\n",
    "def expected_calibration_error(y_true, y_prob, n_bins=10):\n",
    "    # Simple ECE\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_prob = np.asarray(y_prob)\n",
    "\n",
    "    bins = np.linspace(0.0, 1.0, n_bins + 1)\n",
    "    ece = 0.0\n",
    "    for i in range(n_bins):\n",
    "        lo, hi = bins[i], bins[i + 1]\n",
    "        mask = (y_prob >= lo) & (y_prob < hi) if i < n_bins - 1 else (y_prob >= lo) & (y_prob <= hi)\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        acc = y_true[mask].mean()\n",
    "        conf = y_prob[mask].mean()\n",
    "        ece += (mask.sum() / len(y_prob)) * abs(acc - conf)\n",
    "    return float(ece)\n",
    "\n",
    "def evaluate_model(name, model, X_tr, y_tr, X_va, y_va):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    prob_va = model.predict_proba(X_va)[:, 1]\n",
    "\n",
    "    metrics = {\n",
    "        \"model\": name,\n",
    "        \"roc_auc\": float(roc_auc_score(y_va, prob_va)),\n",
    "        \"pr_auc\": float(average_precision_score(y_va, prob_va)),\n",
    "        \"log_loss\": float(log_loss(y_va, prob_va)),\n",
    "        \"brier\": float(brier_score_loss(y_va, prob_va)),\n",
    "        \"ks\": ks_statistic(y_va, prob_va),\n",
    "        \"ece_10bin\": expected_calibration_error(y_va, prob_va, n_bins=10),\n",
    "    }\n",
    "    return metrics, model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45acfa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost not available, skipping. ModuleNotFoundError - No module named 'xgboost'\n",
      "LightGBM not available, skipping. ModuleNotFoundError - No module named 'lightgbm'\n",
      "Models to train: ['LogReg', 'RandomForest', 'HistGB']\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "\n",
    "# 1) Logistic Regression (strong baseline)\n",
    "models.append((\"LogReg\", LogisticRegression(max_iter=5000, class_weight=\"balanced\", n_jobs=None)))\n",
    "\n",
    "# 2) Random Forest (robust, non-linear)\n",
    "models.append((\"RandomForest\", RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    max_depth=None,\n",
    "    min_samples_leaf=2,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")))\n",
    "\n",
    "# 3) Gradient boosting (sklearn) as reliable fallback\n",
    "models.append((\"HistGB\", HistGradientBoostingClassifier(\n",
    "    max_depth=6,\n",
    "    learning_rate=0.07,\n",
    "    max_iter=300,\n",
    "    random_state=42\n",
    ")))\n",
    "\n",
    "# 4) Optional: XGBoost if installed\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    models.append((\"XGBoost\", XGBClassifier(\n",
    "        n_estimators=600,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=4,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_lambda=1.0,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )))\n",
    "except Exception as e:\n",
    "    print(\"XGBoost not available, skipping.\", type(e).__name__, \"-\", e)\n",
    "\n",
    "# 5) Optional: LightGBM if installed\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "    models.append((\"LightGBM\", lgb.LGBMClassifier(\n",
    "        n_estimators=800,\n",
    "        learning_rate=0.03,\n",
    "        num_leaves=31,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )))\n",
    "except Exception as e:\n",
    "    print(\"LightGBM not available, skipping.\", type(e).__name__, \"-\", e)\n",
    "\n",
    "print(\"Models to train:\", [m[0] for m in models])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ec30cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogReg => ROC-AUC: 0.7085 | PR-AUC: 0.4901 | ECE: 0.2338\n",
      "RandomForest => ROC-AUC: 0.7698 | PR-AUC: 0.5526 | ECE: 0.0418\n",
      "HistGB => ROC-AUC: 0.7784 | PR-AUC: 0.5565 | ECE: 0.0075\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "trained_models = {}\n",
    "\n",
    "for name, model in models:\n",
    "    metrics, fitted = evaluate_model(name, model, X_train, y_train, X_val, y_val)\n",
    "    results.append(metrics)\n",
    "    trained_models[name] = fitted\n",
    "    print(name, \"=> ROC-AUC:\", round(metrics[\"roc_auc\"], 4), \"| PR-AUC:\", round(metrics[\"pr_auc\"], 4), \"| ECE:\", round(metrics[\"ece_10bin\"], 4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c99898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "      <th>log_loss</th>\n",
       "      <th>brier</th>\n",
       "      <th>ks</th>\n",
       "      <th>ece_10bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HistGB</td>\n",
       "      <td>0.778389</td>\n",
       "      <td>0.556500</td>\n",
       "      <td>0.430233</td>\n",
       "      <td>0.135259</td>\n",
       "      <td>0.427061</td>\n",
       "      <td>0.007453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>0.769837</td>\n",
       "      <td>0.552647</td>\n",
       "      <td>0.440167</td>\n",
       "      <td>0.138840</td>\n",
       "      <td>0.414130</td>\n",
       "      <td>0.041784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>0.708464</td>\n",
       "      <td>0.490074</td>\n",
       "      <td>0.607468</td>\n",
       "      <td>0.208840</td>\n",
       "      <td>0.358291</td>\n",
       "      <td>0.233846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model   roc_auc    pr_auc  log_loss     brier        ks  ece_10bin\n",
       "0        HistGB  0.778389  0.556500  0.430233  0.135259  0.427061   0.007453\n",
       "1  RandomForest  0.769837  0.552647  0.440167  0.138840  0.414130   0.041784\n",
       "2        LogReg  0.708464  0.490074  0.607468  0.208840  0.358291   0.233846"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leaderboard = pd.DataFrame(results).sort_values(\n",
    "    by=[\"roc_auc\", \"log_loss\", \"ece_10bin\"],\n",
    "    ascending=[False, True, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "leaderboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0fbed196",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner: HistGB\n"
     ]
    }
   ],
   "source": [
    "winner_name = leaderboard.loc[0, \"model\"]\n",
    "winner_model = trained_models[winner_name]\n",
    "print(\"Winner:\", winner_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3a17267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved leaderboard.csv and best model joblib\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(\"../artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"../artifacts/reports\", exist_ok=True)\n",
    "os.makedirs(\"../artifacts/metrics\", exist_ok=True)\n",
    "\n",
    "leaderboard.to_csv(\"../artifacts/reports/leaderboard.csv\", index=False)\n",
    "joblib.dump(winner_model, f\"../artifacts/models/best_model_{winner_name}.joblib\")\n",
    "\n",
    "print(\"Saved leaderboard.csv and best model joblib\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d627e970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'HistGB+Calibrated(Isotonic)',\n",
       " 'roc_auc': 0.7779336021148604,\n",
       " 'pr_auc': 0.555210255695134,\n",
       " 'log_loss': 0.43035102264405684,\n",
       " 'brier': 0.13523625917416685,\n",
       " 'ks': 0.42346991350365126,\n",
       " 'ece_10bin': 0.007188521587524174}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "calibrator = CalibratedClassifierCV(winner_model, method=\"isotonic\", cv=3)\n",
    "calibrator.fit(X_train, y_train)\n",
    "\n",
    "prob_cal = calibrator.predict_proba(X_val)[:, 1]\n",
    "\n",
    "cal_metrics = {\n",
    "    \"model\": f\"{winner_name}+Calibrated(Isotonic)\",\n",
    "    \"roc_auc\": float(roc_auc_score(y_val, prob_cal)),\n",
    "    \"pr_auc\": float(average_precision_score(y_val, prob_cal)),\n",
    "    \"log_loss\": float(log_loss(y_val, prob_cal)),\n",
    "    \"brier\": float(brier_score_loss(y_val, prob_cal)),\n",
    "    \"ks\": ks_statistic(y_val, prob_cal),\n",
    "    \"ece_10bin\": expected_calibration_error(y_val, prob_cal, n_bins=10),\n",
    "}\n",
    "\n",
    "cal_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a25296",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved calibrator.joblib and calibrated_winner_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(calibrator, \"../artifacts/models/calibrator.joblib\")\n",
    "pd.DataFrame([cal_metrics]).to_csv(\"../artifacts/metrics/calibrated_winner_metrics.csv\", index=False)\n",
    "\n",
    "print(\"Saved calibrator.joblib and calibrated_winner_metrics.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f382f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved../artifacts/metrics/run_summary.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kd/_lg1rgc95q34ml7nlvm9s10r0000gp/T/ipykernel_74069/4042472402.py:7: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n"
     ]
    }
   ],
   "source": [
    "import json, os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"../artifacts/metrics\", exist_ok=True)\n",
    "\n",
    "run_summary = {\n",
    "    \"timestamp_utc\": datetime.utcnow().isoformat() + \"Z\",\n",
    "    \"dataset\": \"UCI Default of Credit Card Clients\",\n",
    "    \"models_trained\": leaderboard[\"model\"].tolist(),\n",
    "    \"leaderboard\": leaderboard.to_dict(orient=\"records\"),\n",
    "    \"winner\": winner_name,\n",
    "}\n",
    "\n",
    "# add calibrated metrics if you computed them\n",
    "try:\n",
    "    run_summary[\"calibrated_winner_metrics\"] = cal_metrics\n",
    "except NameError:\n",
    "    run_summary[\"calibrated_winner_metrics\"] = None\n",
    "\n",
    "with open(\"../artifacts/metrics/run_summary.json\", \"w\") as f:\n",
    "    json.dump(run_summary, f, indent=2)\n",
    "\n",
    "print(\"Saved../artifacts/metrics/run_summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a1c53ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "import json, os\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c3ba2d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "def summarize_search(search, model_name):\n",
    "    best = search.best_estimator_\n",
    "    best_params = search.best_params_\n",
    "    best_cv = float(search.best_score_)\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"best_cv_roc_auc\": best_cv,\n",
    "        \"best_params\": best_params\n",
    "    }, best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f13720ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LogReg_Tuned', 'RandomForest_Tuned', 'HistGB_Tuned']\n"
     ]
    }
   ],
   "source": [
    "search_spaces = []\n",
    "\n",
    "# 1) Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=8000, class_weight=\"balanced\")\n",
    "logreg_space = {\n",
    "    \"C\": np.logspace(-3, 2, 40),\n",
    "    \"penalty\": [\"l2\"],\n",
    "    \"solver\": [\"lbfgs\"]\n",
    "}\n",
    "search_spaces.append((\"LogReg_Tuned\", logreg, logreg_space, 30))\n",
    "\n",
    "# 2) Random Forest\n",
    "rf = RandomForestClassifier(class_weight=\"balanced_subsample\", random_state=42, n_jobs=-1)\n",
    "rf_space = {\n",
    "    \"n_estimators\": [200, 400, 600, 800],\n",
    "    \"max_depth\": [None, 4, 6, 8, 12, 16],\n",
    "    \"min_samples_leaf\": [1, 2, 4, 8],\n",
    "    \"max_features\": [\"sqrt\", \"log2\", None],\n",
    "}\n",
    "search_spaces.append((\"RandomForest_Tuned\", rf, rf_space, 25))\n",
    "\n",
    "# 3) HistGradientBoosting\n",
    "hgb = HistGradientBoostingClassifier(random_state=42)\n",
    "hgb_space = {\n",
    "    \"learning_rate\": [0.01, 0.03, 0.05, 0.07, 0.1],\n",
    "    \"max_depth\": [3, 4, 5, 6, 8],\n",
    "    \"max_iter\": [200, 300, 500, 800],\n",
    "    \"min_samples_leaf\": [20, 50, 100]\n",
    "}\n",
    "search_spaces.append((\"HistGB_Tuned\", hgb, hgb_space, 25))\n",
    "\n",
    "print([s[0] for s in search_spaces])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c311222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Tuning: LogReg_Tuned ===\n",
      "Fitting 3 folds for each of 30 candidates, totalling 90 fits\n",
      "Best CV ROC-AUC: 0.7262\n",
      "Val ROC-AUC: 0.7085 | Val PR-AUC: 0.4901\n",
      "Best params: {'solver': 'lbfgs', 'penalty': 'l2', 'C': np.float64(0.2728333376486767)}\n",
      "\n",
      "=== Tuning: RandomForest_Tuned ===\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Best CV ROC-AUC: 0.7838\n",
      "Val ROC-AUC: 0.777 | Val PR-AUC: 0.5544\n",
      "Best params: {'n_estimators': 600, 'min_samples_leaf': 8, 'max_features': 'log2', 'max_depth': 12}\n",
      "\n",
      "=== Tuning: HistGB_Tuned ===\n",
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "Best CV ROC-AUC: 0.7827\n",
      "Val ROC-AUC: 0.7809 | Val PR-AUC: 0.5547\n",
      "Best params: {'min_samples_leaf': 50, 'max_iter': 200, 'max_depth': 8, 'learning_rate': 0.03}\n"
     ]
    }
   ],
   "source": [
    "tuning_results = []\n",
    "tuned_models = {}\n",
    "\n",
    "for name, estimator, space, n_iter in search_spaces:\n",
    "    print(\"\\n=== Tuning:\", name, \"===\")\n",
    "\n",
    "    search = RandomizedSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_distributions=space,\n",
    "        n_iter=n_iter,\n",
    "        scoring=\"roc_auc\",\n",
    "        cv=cv,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    search.fit(X_train, y_train)\n",
    "    summary, best_model = summarize_search(search, name)\n",
    "\n",
    "    # Evaluate best model on validation set\n",
    "    prob_val = best_model.predict_proba(X_val)[:, 1]\n",
    "    summary.update({\n",
    "        \"val_roc_auc\": float(roc_auc_score(y_val, prob_val)),\n",
    "        \"val_pr_auc\": float(average_precision_score(y_val, prob_val)),\n",
    "        \"val_log_loss\": float(log_loss(y_val, prob_val)),\n",
    "        \"val_brier\": float(brier_score_loss(y_val, prob_val)),\n",
    "    })\n",
    "\n",
    "    tuning_results.append(summary)\n",
    "    tuned_models[name] = best_model\n",
    "\n",
    "    print(\"Best CV ROC-AUC:\", round(summary[\"best_cv_roc_auc\"], 4))\n",
    "    print(\"Val ROC-AUC:\", round(summary[\"val_roc_auc\"], 4), \"| Val PR-AUC:\", round(summary[\"val_pr_auc\"], 4))\n",
    "    print(\"Best params:\", summary[\"best_params\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32df9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuning_leaderboard.csv, tuning_run.json, and best tuned model: HistGB_Tuned\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_cv_roc_auc</th>\n",
       "      <th>best_params</th>\n",
       "      <th>val_roc_auc</th>\n",
       "      <th>val_pr_auc</th>\n",
       "      <th>val_log_loss</th>\n",
       "      <th>val_brier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HistGB_Tuned</td>\n",
       "      <td>0.782726</td>\n",
       "      <td>{'min_samples_leaf': 50, 'max_iter': 200, 'max...</td>\n",
       "      <td>0.780908</td>\n",
       "      <td>0.554696</td>\n",
       "      <td>0.428975</td>\n",
       "      <td>0.134902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForest_Tuned</td>\n",
       "      <td>0.783761</td>\n",
       "      <td>{'n_estimators': 600, 'min_samples_leaf': 8, '...</td>\n",
       "      <td>0.777017</td>\n",
       "      <td>0.554428</td>\n",
       "      <td>0.513692</td>\n",
       "      <td>0.166692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg_Tuned</td>\n",
       "      <td>0.726165</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.27...</td>\n",
       "      <td>0.708451</td>\n",
       "      <td>0.490059</td>\n",
       "      <td>0.607487</td>\n",
       "      <td>0.208848</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                model  best_cv_roc_auc  \\\n",
       "0        HistGB_Tuned         0.782726   \n",
       "1  RandomForest_Tuned         0.783761   \n",
       "2        LogReg_Tuned         0.726165   \n",
       "\n",
       "                                         best_params  val_roc_auc  val_pr_auc  \\\n",
       "0  {'min_samples_leaf': 50, 'max_iter': 200, 'max...     0.780908    0.554696   \n",
       "1  {'n_estimators': 600, 'min_samples_leaf': 8, '...     0.777017    0.554428   \n",
       "2  {'solver': 'lbfgs', 'penalty': 'l2', 'C': 0.27...     0.708451    0.490059   \n",
       "\n",
       "   val_log_loss  val_brier  \n",
       "0      0.428975   0.134902  \n",
       "1      0.513692   0.166692  \n",
       "2      0.607487   0.208848  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "os.makedirs(\"../artifacts/reports\", exist_ok=True)\n",
    "os.makedirs(\"../artifacts/models\", exist_ok=True)\n",
    "os.makedirs(\"../artifacts/metrics\", exist_ok=True)\n",
    "\n",
    "tuning_df = pd.DataFrame(tuning_results).sort_values(\n",
    "    by=[\"val_roc_auc\", \"val_log_loss\"],\n",
    "    ascending=[False, True]\n",
    ").reset_index(drop=True)\n",
    "\n",
    "tuning_df.to_csv(\"../artifacts/reports/tuning_leaderboard.csv\", index=False)\n",
    "\n",
    "run = {\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"tuning_results\": tuning_results\n",
    "}\n",
    "\n",
    "with open(\"../artifacts/metrics/tuning_run.json\", \"w\") as f:\n",
    "    json.dump(run, f, indent=2)\n",
    "\n",
    "best_tuned_name = tuning_df.loc[0, \"model\"]\n",
    "best_tuned_model = tuned_models[best_tuned_name]\n",
    "\n",
    "joblib.dump(best_tuned_model, f\"../artifacts/models/best_tuned_model_{best_tuned_name}.joblib\")\n",
    "\n",
    "print(\"Saved tuning_leaderboard.csv, tuning_run.json, and best tuned model:\", best_tuned_name)\n",
    "tuning_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e94b7b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calibrated tuned model metrics:\n",
      "ROC-AUC: 0.7792445853305017\n",
      "PR-AUC: 0.5549157543663917\n",
      "LogLoss: 0.43016152223295673\n",
      "Brier: 0.13520135189985455\n",
      "Saved ../artifacts/models/calibrator_tuned.joblib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, log_loss, brier_score_loss\n",
    "\n",
    "# Load processed data\n",
    "X_train = pd.read_csv(\"../data/processed/X_train.csv\")\n",
    "X_val   = pd.read_csv(\"../data/processed/X_val.csv\")\n",
    "y_train = pd.read_csv(\"../data/processed/y_train.csv\").squeeze(\"columns\")\n",
    "y_val   = pd.read_csv(\"../data/processed/y_val.csv\").squeeze(\"columns\")\n",
    "\n",
    "# Load tuned best model\n",
    "best_tuned = joblib.load(\"../artifacts/models/best_tuned_model_HistGB_Tuned.joblib\")\n",
    "\n",
    "# Calibrate\n",
    "calibrator_tuned = CalibratedClassifierCV(best_tuned, method=\"isotonic\", cv=3)\n",
    "calibrator_tuned.fit(X_train, y_train)\n",
    "\n",
    "# Validate calibrated PDs\n",
    "pd_val_tuned = calibrator_tuned.predict_proba(X_val)[:, 1]\n",
    "\n",
    "print(\"Calibrated tuned model metrics:\")\n",
    "print(\"ROC-AUC:\", roc_auc_score(y_val, pd_val_tuned))\n",
    "print(\"PR-AUC:\", average_precision_score(y_val, pd_val_tuned))\n",
    "print(\"LogLoss:\", log_loss(y_val, pd_val_tuned))\n",
    "print(\"Brier:\", brier_score_loss(y_val, pd_val_tuned))\n",
    "\n",
    "# Save calibrator\n",
    "joblib.dump(calibrator_tuned, \"../artifacts/models/calibrator_tuned.joblib\")\n",
    "print(\"Saved ../artifacts/models/calibrator_tuned.joblib\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
